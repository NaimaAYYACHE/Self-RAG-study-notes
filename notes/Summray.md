# ğŸ§  SELF-RAG â€” Self-Reflective Retrieval-Augmented Generation

**Paper:** *Selfâ€‘RAG: Learning to Retrieve, Generate, and Critique through Selfâ€‘Reflection* (Akari Asai et al., arXiv 2310.11511)

---

## ğŸŒŸ What is SELF-RAG?

**SELF-RAG** is an advanced LLM framework that **retrieves information on-demand, generates answers, and self-reflects** ğŸªğŸ§ . It improves factuality, relevance, and transparency over standard RAG systems.

- ğŸ” **Retrieval:** Fetches supporting documents only when needed.
- âœï¸ **Generation:** Writes fluent text using both memory and retrieved info.
- ğŸ’­ **Self-Reflection:** Uses **reflection tokens** to evaluate relevance, support, and usefulness.

> **In short:** *Think, check, correct, repeat!* ğŸ”„âœ…

---

## ğŸ›  How it Works

1. **Adaptive Retrieval**  
   - `[RETRIEVE]` â†’ â€œNeed docsâ€  
   - `[NO_RETRIEVE]` â†’ â€œI know enoughâ€  
   - `[CONTINUE]` â†’ â€œUse previous evidenceâ€  

2. **Generator Model (M) âœï¸ğŸ¤–**  
   - Writes answers **and predicts reflection tokens**: `[ISREL] âœ… [ISSUP] ğŸ“– [ISUSE] â­`  
   - Decides **what to retrieve**, **what is relevant**, and **what is supported**  

3. **Critic Model (C) ğŸ‘©â€ğŸ«**  
   - Labels data with reflection tokens **during training only**  
   - Teaches the Generator **how to self-reflect**  

4. **Reflection Tokens ğŸª**  

| Token | Purpose |
| --- | --- |
| `[RETRIEVE]` ğŸ” | Trigger retrieval |
| `[ISREL]` âœ… | Relevance of doc |
| `[ISSUP]` ğŸ“– | Supported by evidence |
| `[ISUSE]` â­ | Usefulness of output |

---

## âš¡ SELF-RAG Pipeline (Simplified)

1. **User Query** â†’ â€œWhat did Morocco achieve in 2022 FIFA WC?â€ âš½ğŸ‡²ğŸ‡¦  
2. **Generator checks memory** â†’ `[RETRIEVE=YES]` ğŸ”  
3. **Retriever fetches documents** ğŸ“„ğŸ“‘  
4. **Generator evaluates relevance** â†’ `[ISREL]`  
5. **Generator produces answer** â†’ `[ISSUP]` for support, `[ISUSE]` for usefulness  
6. **Optional second retrieval** `[RETRIEVE=CONTINUE]` ğŸ”„  
7. **Final output** â†’ Factually supported, relevant, useful âœ…ğŸ’¡  

**Example Output:**  
[RETRIEVE=YES] Morocco reached the semifinals in 2022. [ISREL=1] âœ… [ISSUP=1] ğŸ“– [ISUSE=5] â­â­â­â­â­

---

## ğŸ“Š Key Advantages

- âœ… Adaptive retrieval â†’ efficient & cost-saving  
- âœ… Self-reflection â†’ fewer hallucinations  
- âœ… Controllable inference â†’ balance factuality vs fluency ğŸ›ï¸  
- âœ… Outperforms larger RAG models using smarter reasoning, not just scale ğŸ†  

---

## ğŸ—‚ Whatâ€™s in this repo

- **`notes/`** ğŸ“  
  - Self RAG overview.md  
  - Architecture schema Self RAG.md  
  - Reflection tokens.md  
  - Controllable Decoding in Self RAG.md  
  - Summary.md (this file)  

- **`reports/`** ğŸ“„  
  - SELF RAG Study Guide.md  
  - Self RAG report.md  

> Based on the research paper by Akari Asai et al.  
> Links to key references and papers are included for deeper reading:  
> - [SELF-RAG Paper](https://arxiv.org/abs/2310.11511)  
> - [GitHub Repo](https://github.com/AkariAsai/self-rag)  
> - [Medium Briefing](https://cobusgreyling.medium.com/self-reflective-retrieval-augmented-generation-self-rag-f5cbad4412d5)

---

**ğŸ’¡ Takeaway:**  
SELF-RAG = **adaptive retrieval + generation + self-reflection** â†’ more **factual, transparent, and controllable** LLM outputs ğŸš€ğŸ§ 
